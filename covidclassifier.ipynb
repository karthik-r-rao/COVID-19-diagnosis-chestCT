{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "covidclassifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "89SqAJvZks3v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2c49d467-18c5-4dbc-99b7-fe158e411512"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import random\n",
        "import copy\n",
        "import shutil\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deMC6cSqckcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "class mymodel(nn.Module):\n",
        "\n",
        "  def blocktype1(self, in_channels, out_channels, kernel=5):\n",
        "    block = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(kernel_size=kernel, in_channels=in_channels, out_channels=in_channels, padding=2, stride=1),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.BatchNorm2d(in_channels),\n",
        "        torch.nn.Dropout2d(p=0.15),\n",
        "        torch.nn.Conv2d(kernel_size=kernel, in_channels=in_channels, out_channels=out_channels, padding=2, stride=1 ),\n",
        "        torch.nn.ReLU()\n",
        "    )\n",
        "    return block\n",
        "\n",
        "  def blocktype2(self, in_channels, out_channels, kernel=3):\n",
        "    block = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(kernel_size=kernel, in_channels=in_channels, out_channels=in_channels, stride=1, padding=1),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Conv2d(kernel_size=kernel, in_channels=in_channels, out_channels=in_channels, stride=1, padding=1),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.BatchNorm2d(in_channels),\n",
        "        torch.nn.Dropout2d(p=0.2),\n",
        "        torch.nn.Conv2d(kernel_size=kernel, in_channels=in_channels, out_channels=out_channels, stride=1, padding=1),\n",
        "        torch.nn.ReLU()\n",
        "    )\n",
        "    return block\n",
        "\n",
        "  def blocktype3(self, in_channels, out_channels, kernel=7):\n",
        "    block = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(kernel_size=kernel, in_channels=in_channels, out_channels=in_channels, padding=3, stride=1),\n",
        "        torch.nn.ReLU(), \n",
        "        torch.nn.BatchNorm2d(in_channels),\n",
        "        torch.nn.Dropout2d(p=0.1),\n",
        "        torch.nn.Conv2d(kernel_size=kernel, in_channels=in_channels, out_channels=out_channels, padding=3, stride=1),\n",
        "        torch.nn.ReLU()\n",
        "    )\n",
        "    return block\n",
        "\n",
        "  def special_convolutions(self, in_channels, out_channels, step, kernel=3):\n",
        "    block = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(kernel_size=kernel, in_channels = in_channels, out_channels=out_channels, padding=1, stride=2**step)\n",
        "    )\n",
        "    return block\n",
        "\n",
        "  def fclayer(self, in_features, out_features):\n",
        "    layer = torch.nn.Sequential(\n",
        "        torch.nn.Linear(in_features=in_features, out_features=out_features),\n",
        "        torch.nn.BatchNorm1d(num_features=out_features),\n",
        "        torch.nn.Dropout(p=0.25),\n",
        "        torch.nn.ReLU()\n",
        "    )\n",
        "    return layer\n",
        "\n",
        "  def pointwiseconv(self, in_channels, out_channels):\n",
        "    layer = torch.nn.Conv2d(kernel_size=1, in_channels=in_channels, out_channels=out_channels)\n",
        "    return layer\n",
        "\n",
        "  def __init__(self):\n",
        "    super(mymodel, self).__init__()\n",
        "    self.first = self.pointwiseconv(3,4)\n",
        "    self.resize1 = self.special_convolutions(4,128,step=1)\n",
        "    self.resize2 = self.special_convolutions(4,512,step=4)\n",
        "    self.conv1 = self.blocktype3(4,64)\n",
        "    self.p1 = self.pointwiseconv(4,64)\n",
        "    self.maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.conv2 = self.blocktype1(64,128)\n",
        "    self.p2 = self.pointwiseconv(64,128)\n",
        "    self.maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.conv3 = self.blocktype1(128,256)\n",
        "    self.p3 = self.pointwiseconv(128,256)\n",
        "    self.maxpool3 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.conv4 = self.blocktype2(256,256)\n",
        "    self.maxpool4 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.conv5 = self.blocktype2(256,512)\n",
        "    self.p5 = self.pointwiseconv(256,512)\n",
        "    self.conv6 = self.blocktype2(512,512)\n",
        "    self.conv7 = self.blocktype2(512,1024)\n",
        "    self.maxpool5 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.fc1 = self.fclayer(7*7*1024,64)\n",
        "    self.fc2 = self.fclayer(64,2)\n",
        "    self.fc3 = self.fclayer(16,2)\n",
        "\n",
        "  def activations_hook(self, grad):\n",
        "    self.gradients = grad\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.first(x)\n",
        "    r1 = self.resize1(x)\n",
        "    r2 = self.resize2(x)\n",
        "    x1 = self.conv1(x)\n",
        "    x = self.p1(x)\n",
        "    x = x+x1\n",
        "    x = self.maxpool1(x)\n",
        "\n",
        "    x1 = self.conv2(x)\n",
        "    x = self.p2(x)\n",
        "    x = x+x1\n",
        "    x = x+r1\n",
        "    x = self.maxpool2(x)\n",
        "\n",
        "    x1 = self.conv3(x)\n",
        "    x = self.p3(x)\n",
        "    x = x+x1\n",
        "    x = self.maxpool3(x)\n",
        "\n",
        "    x1 = self.conv4(x)\n",
        "    x = x+x1\n",
        "    x = self.maxpool4(x)\n",
        "\n",
        "    x1 = self.conv5(x)\n",
        "    x = self.p5(x)\n",
        "    x = x+x1\n",
        "    x = x+r2\n",
        "    x1 = self.conv6(x)\n",
        "    x = x+x1\n",
        "    xdash = self.conv7(x)\n",
        "    #hook = xdash.register_hook(self.activations_hook)  #comment this line when training\n",
        "    x = self.maxpool5(xdash)\n",
        "    x = torch.flatten(x, 1)\n",
        "    fclayer1 = self.fc1(x)\n",
        "    fclayer2 = self.fc2(fclayer1)\n",
        "    #fclayer3 = self.fc3(fclayer2)\n",
        "    return fclayer2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnJH-RWuk4KN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"use_gpu = torch.cuda.is_available()\n",
        "\n",
        "class mymodel(nn.Module):\n",
        "\n",
        "  def blocktype1(self, in_channels, out_channels, kernel=5):\n",
        "    block = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(kernel_size=kernel, in_channels=in_channels, out_channels=in_channels, padding=2, stride=1),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Conv2d(kernel_size=kernel, in_channels=in_channels, out_channels=out_channels, stride=1, padding=2),\n",
        "        torch.nn.BatchNorm2d(out_channels),\n",
        "        torch.nn.ReLU()\n",
        "    )\n",
        "    return block\n",
        "\n",
        "  def blocktype2(self, in_channels, out_channels, kernel=3):\n",
        "    block = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(kernel_size=kernel, in_channels=in_channels, out_channels=in_channels, stride=1, padding=1),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Conv2d(kernel_size=kernel, in_channels=in_channels, out_channels=in_channels, stride=1, padding=1),\n",
        "        torch.nn.LeakyReLU(),\n",
        "        torch.nn.Conv2d(kernel_size=kernel, in_channels=in_channels, out_channels=out_channels, stride=1, padding=1),\n",
        "        torch.nn.BatchNorm2d(out_channels),\n",
        "        torch.nn.ReLU()\n",
        "    )\n",
        "    return block\n",
        "\n",
        "  def fclayer(self, in_features, out_features):\n",
        "    layer = torch.nn.Sequential(\n",
        "        torch.nn.Linear(in_features=in_features, out_features=out_features),\n",
        "        torch.nn.BatchNorm1d(out_features),\n",
        "        torch.nn.ReLU()\n",
        "    )\n",
        "    return layer\n",
        "\n",
        "  def pointwiseconv(self, in_channels, out_channels):\n",
        "    layer = torch.nn.Conv2d(kernel_size=1, in_channels=in_channels, out_channels=out_channels)\n",
        "    return layer\n",
        "\n",
        "  def __init__(self):\n",
        "    super(mymodel, self).__init__()\n",
        "    self.conv1 = self.blocktype1(3, 64)\n",
        "    self.p1 = self.pointwiseconv(3,64)\n",
        "    self.maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv2 = self.blocktype1(64,128)\n",
        "    self.p2 = self.pointwiseconv(64,128)\n",
        "    self.maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv3 = self.blocktype2(128,256)\n",
        "    self.p3 = self.pointwiseconv(128,256)\n",
        "    self.maxpool3 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv4 = self.blocktype2(256,512)\n",
        "    self.p4 = self.pointwiseconv(256,512)\n",
        "    self.maxpool4 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv5 = self.blocktype2(512,512)\n",
        "    self.p5 = self.pointwiseconv(512,512)\n",
        "    self.conv6 = self.blocktype2(512,512)\n",
        "    self.maxpool5 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "    self.fc1 = self.fclayer(7*7*512, 64)\n",
        "    self.fc2 = self.fclayer(64,2)\n",
        "    self.gradients = None\n",
        "\n",
        "  def activations_hook(self, grad):\n",
        "    self.gradients = grad\n",
        "\n",
        "  def forward(self, x):\n",
        "    x1 = self.conv1(x)\n",
        "    x = self.p1(x)\n",
        "    x+=x1\n",
        "    x = self.maxpool1(x)\n",
        "    x1 = self.conv2(x)\n",
        "    x = self.p2(x)\n",
        "    x+=x1\n",
        "    x = self.maxpool2(x)\n",
        "    x1 = self.conv3(x)\n",
        "    x = self.p3(x)\n",
        "    x+=x1\n",
        "    x = self.maxpool3(x)\n",
        "    x1 = self.conv4(x)\n",
        "    x = self.p4(x)\n",
        "    x+=x1\n",
        "    x = self.maxpool4(x)\n",
        "    x1 = self.conv5(x)\n",
        "    x = self.p5(x)\n",
        "    x+=x1\n",
        "    xdash = self.conv6(x)\n",
        "    #hook = xdash.register_hook(self.activations_hook)  #comment this line when training\n",
        "    x = self.maxpool5(xdash)\n",
        "    x = torch.flatten(x, 1)\n",
        "    fclayer1 = self.fc1(x)\n",
        "    fclayer2 = self.fc2(fclayer1)\n",
        "    return fclayer2\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG04JHcKydwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs):\n",
        "  val_loss_history = []\n",
        "  train_loss_history = []\n",
        "  train_acc_history = []\n",
        "  val_acc_history = []\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_acc = 0\n",
        "  for epoch in range(num_epochs):\n",
        "    print(f\"Epoch Number: {epoch+1} / {num_epochs}\")\n",
        "\n",
        "    for phase in ['train','val']:\n",
        "      if phase == \"train\":\n",
        "        model.train()\n",
        "      else:\n",
        "        model.eval()\n",
        "      running_loss = 0\n",
        "      running_corrects = 0\n",
        "      for inputs, labels in dataloaders[phase]:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with torch.set_grad_enabled(phase == \"train\"):\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          _,preds = torch.max(outputs, 1)\n",
        "          if phase == \"train\":\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()*inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)  \n",
        "\n",
        "      if phase==\"val\":\n",
        "          scheduler.step(epoch_loss)\n",
        "      \n",
        "\n",
        "      epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "      epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "      print(f'{phase} loss: {epoch_loss} and acc: {epoch_acc}')\n",
        "\n",
        "      if phase == \"val\" and epoch_acc>best_acc:\n",
        "        best_acc = epoch_acc\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "      if phase == \"val\":\n",
        "        val_loss_history.append(epoch_loss)\n",
        "        val_acc_history.append(epoch_acc)\n",
        "      if phase == \"train\":\n",
        "        train_loss_history.append(epoch_loss)\n",
        "        train_acc_history.append(epoch_acc)\n",
        "    print()\n",
        "  \n",
        "  print(f'Best val acc: {best_acc}')\n",
        "  model.load_state_dict(best_model_wts)\n",
        "  return model, val_loss_history, train_loss_history, val_acc_history, train_acc_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXgYlRsEyrLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if use_gpu:\n",
        "  device = torch.device(\"cuda:0\")\n",
        "model = mymodel()\n",
        "model = model.to(device)\n",
        "num_classes = 2\n",
        "input_size = 224\n",
        "batch_size = 32\n",
        "num_epochs = 400\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.05) #weight_decay implements L2 regularization\n",
        "weights = torch.tensor([1.0,234/191]).cuda()\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.75, patience=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92aP9gXmmF0o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6be3c19f-e184-41d6-fc10-ce0be8755405"
      },
      "source": [
        "data_dir = \"\n",
        "train_transforms = transforms.Compose([transforms.Resize((input_size, input_size)), transforms.ToTensor()])\n",
        "train_data = torchvision.datasets.ImageFolder(root=data_dir + 'train/', transform=train_transforms)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle = False)\n",
        "\n",
        "train_mean = []\n",
        "train_std = []\n",
        "for i, data in enumerate(train_dataloader, 0):\n",
        "    # shape (batch_size, 3, height, width)\n",
        "    numpy_image = data[0].numpy()\n",
        "    batch_mean = np.mean(numpy_image, axis=(0,2,3))\n",
        "    batch_std = np.std(numpy_image, axis=(0,2,3))\n",
        "    train_mean.append(batch_mean)\n",
        "    train_std.append(batch_std)\n",
        "\n",
        "train_mean = np.array(train_mean).mean(axis=0)\n",
        "train_std = np.array(train_std).mean(axis=0)\n",
        "print(train_mean, train_std)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5980851  0.59779495 0.5975965 ] [0.3109232  0.310951   0.31100973]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MWss347yvCn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "364259a1-fcc0-496a-a48a-b1421fffd804"
      },
      "source": [
        "data_dir = \"\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((input_size,input_size)),\n",
        "        transforms.RandomRotation((-15,15)),\n",
        "        transforms.ColorJitter(brightness=0.25, contrast=0.15),\n",
        "        transforms.RandomAffine(0, translate=None, scale=[0.5,1.5], shear=None, resample=False, fillcolor=0),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(train_mean,train_std)]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(train_mean, train_std)])\n",
        "}   \n",
        "\n",
        "train_data = torchvision.datasets.ImageFolder(root=data_dir + 'train/', transform=data_transforms['train'])\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, num_workers=4, shuffle = True)\n",
        "val_data = torchvision.datasets.ImageFolder(root=data_dir + 'val/', transform=data_transforms['val'])\n",
        "val_dataloader = torch.utils.data.DataLoader(val_data, batch_size = batch_size, num_workers=4, shuffle = True)\n",
        "x = train_data.class_to_idx\n",
        "print(x)\n",
        "x = val_data.class_to_idx\n",
        "print(x)\n",
        "\n",
        "dataloaders_dict = {'train':train_dataloader, 'val':val_dataloader}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'negative': 0, 'positive': 1}\n",
            "{'negative': 0, 'positive': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAd9tb-Gyz2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, vhist, thist, vacc, tacc = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDFN-0tey356",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vhist = [v for v in vhist]\n",
        "thist = [t for t in thist]\n",
        "\n",
        "vacc = [v for v in vacc]\n",
        "tacc = [t for t in tacc]\n",
        "\n",
        "plt.plot(np.arange(num_epochs)+1, thist, 'r', label=\"Training loss\")\n",
        "plt.plot(np.arange(num_epochs)+1, vhist, 'g', label=\"Validation loss\")\n",
        "plt.ylim(0,1) \n",
        "plt.legend(loc = \"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpXPMJHEZmyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(np.arange(num_epochs)+1, tacc, 'r', label=\"Training acc\")\n",
        "plt.plot(np.arange(num_epochs)+1, vacc, 'g', label=\"Validation acc\")\n",
        "plt.legend(loc = \"lower right\")\n",
        "plt.ylim(0,1) \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcHYIUjj0lxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_transform = transforms.Compose([\n",
        "        transforms.Resize((input_size,input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(train_mean, train_std)])\n",
        "test_data = torchvision.datasets.ImageFolder(root=data_dir + 'test/', transform=test_transform)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size = 4, num_workers=4, shuffle = False)\n",
        "x = test_data.class_to_idx\n",
        "print(x)\n",
        "def predict(model, test_loader, device):\n",
        "    model.eval()\n",
        "    y_true = torch.tensor([], dtype=torch.long, device=device)\n",
        "    all_outputs = torch.tensor([], device=device)\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            inputs = [i.to(device) for i in data[:-1]]\n",
        "            labels = data[-1].to(device)\n",
        "            \n",
        "            outputs = model(*inputs)\n",
        "            y_true = torch.cat((y_true, labels), 0)\n",
        "            all_outputs = torch.cat((all_outputs, outputs), 0)\n",
        "    \n",
        "    y_true = y_true.cpu().numpy()  \n",
        "    _, y_pred = torch.max(all_outputs, 1)\n",
        "    y_pred = y_pred.cpu().numpy()\n",
        "    y_pred_prob = F.softmax(all_outputs, dim=1).cpu().numpy()\n",
        "    \n",
        "    return y_true, y_pred, y_pred_prob\n",
        "\n",
        "y_true, y_pred, y_pred_prob = predict(model, test_dataloader, \"cuda:0\")\n",
        "print(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZlcIKRQ0wo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def true_positives(y_true, y_pred_prob, th):\n",
        "  TP = 0\n",
        "  thresholded_probs = y_pred_prob >= th\n",
        "  TP = np.sum((y_true==1) & (thresholded_probs==1))\n",
        "  return TP\n",
        "\n",
        "def true_negatives(y_true, y_pred_prob, th):\n",
        "  TN = 0\n",
        "  thresholded_probs = y_pred_prob >= th\n",
        "  TN = np.sum((y_true==0) & (thresholded_probs==0))\n",
        "  return TN\n",
        "\n",
        "def false_positives(y_true, y_pred_prob, th):\n",
        "  FP = 0\n",
        "  thresholded_probs = y_pred_prob >= th\n",
        "  FP = np.sum((y_true==0) & (thresholded_probs==1))\n",
        "  return FP\n",
        "\n",
        "def false_negatives(y_true, y_pred_prob, th):\n",
        "  FN = 0\n",
        "  thresholded_probs = y_pred_prob >= th\n",
        "  FN = np.sum((y_true==1) & (thresholded_probs==0))\n",
        "  return FN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14GkTCiG005p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(y_true, y_pred_prob, th):\n",
        "  TP = true_positives(y_true, y_pred_prob, th)\n",
        "  TN = true_negatives(y_true, y_pred_prob, th)\n",
        "  FP = false_positives(y_true, y_pred_prob, th)\n",
        "  FN = false_negatives(y_true, y_pred_prob, th)\n",
        "  accuracy = (TP + TN)/(TP + TN + FP + FN)\n",
        "  return accuracy\n",
        "\n",
        "def get_prevalence(y_true):\n",
        "  prevalence = 0\n",
        "  prevalence = np.sum(y_true)/len(y_true)\n",
        "  return prevalence\n",
        "\n",
        "def get_sensitivity(y_true, y_pred_prob, th):\n",
        "  sensitivity = 0\n",
        "  TP = true_positives(y_true, y_pred_prob, th)\n",
        "  FN = false_negatives(y_true, y_pred_prob, th)\n",
        "  sensitivity = TP / (TP + FN)\n",
        "  return sensitivity\n",
        "\n",
        "def get_specificity(y_true, y_pred_prob, th):\n",
        "  specificity = 0\n",
        "  TN = true_negatives(y_true, y_pred_prob, th)\n",
        "  FP = false_positives(y_true, y_pred_prob, th)\n",
        "  specificity = TN / (TN + FP)\n",
        "  return specificity\n",
        "\n",
        "def get_ppv(y_true, y_pred_prob, th):\n",
        "  ppv = 0\n",
        "  TP = true_positives(y_true, y_pred_prob, th)\n",
        "  FP = false_positives(y_true, y_pred_prob, th)\n",
        "  ppv = TP / (FP + TP)\n",
        "  return ppv\n",
        "\n",
        "def get_npv(y_true, y_pred_prob, th):\n",
        "  npv = 0\n",
        "  TN = true_negatives(y_true, y_pred_prob, th)\n",
        "  FN = false_negatives(y_true, y_pred_prob, th)\n",
        "  npv = TN / (FN + TN)\n",
        "  return npv\n",
        "\n",
        "def get_roc_curve_info(y_true, y_pred_prob):\n",
        "  threshold_set = np.arange(0,1,0.00001)\n",
        "  TPR = np.zeros(len(threshold_set))\n",
        "  FPR = np.zeros(len(threshold_set))\n",
        "  i=0\n",
        "  for th in threshold_set:\n",
        "    TPR[i] = get_sensitivity(y_true, y_pred_prob, th)\n",
        "    spec = get_specificity(y_true, y_pred_prob, th)\n",
        "    FPR[i] = (1 - spec)\n",
        "    i+=1\n",
        "  return TPR, FPR\n",
        "\n",
        "def precision_recall_curve_info(y_true, y_pred_prob):\n",
        "  threshold_set = np.arange(0,1,0.00001)\n",
        "  precision = np.zeros(len(threshold_set))\n",
        "  recall = np.zeros(len(threshold_set))\n",
        "  i=0\n",
        "  for th in threshold_set:\n",
        "    precision[i] = get_ppv(y_true, y_pred_prob, th)\n",
        "    recall[i] = get_sensitivity(y_true, y_pred_prob, th)\n",
        "    i+=1\n",
        "  precision = np.array([i for i in precision if (str(i)!='nan')])\n",
        "  precision = np.concatenate((precision, np.ones(len(recall) - len(precision))))\n",
        "  return precision, recall\n",
        "\n",
        "def get_statistics(y_true, y_pred_prob, th):\n",
        "  accuracy = get_accuracy(y_true, y_pred_prob, th)\n",
        "  prevalence = get_prevalence(y_true)\n",
        "  sensitivity = get_sensitivity(y_true, y_pred_prob, th)\n",
        "  specificity = get_specificity(y_true, y_pred_prob, th)\n",
        "  ppv = get_ppv(y_true, y_pred_prob, th)\n",
        "  npv = get_npv(y_true, y_pred_prob, th)\n",
        "  tpr, fpr = get_roc_curve_info(y_true, y_pred_prob)\n",
        "  AUC = auc(fpr,tpr)\n",
        "  prec_list, rec_list = precision_recall_curve_info(y_true, y_pred_prob)\n",
        "  score = auc(rec_list, prec_list)\n",
        "  f1_score = 2*ppv*sensitivity/(ppv + sensitivity)\n",
        "  stat_dict = {'Accuracy': accuracy, \n",
        "               'Prevalence':prevalence,\n",
        "               'Sensitivity':sensitivity,\n",
        "               'Specificity':specificity,\n",
        "               'PPV':ppv,\n",
        "               'NPV':npv,\n",
        "               'AUC':AUC,\n",
        "               'F1 Score':f1_score,\n",
        "               'Score': score}\n",
        "  return stat_dict, tpr, fpr, prec_list, rec_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exxJmv3t-XBQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "863ce1b1-85de-4052-defd-6b3fe7d88deb"
      },
      "source": [
        "def decide_th(y_true, y_pred_prob):\n",
        "  threshold_set = np.arange(0,1,0.00001)\n",
        "  TPR = np.zeros(len(threshold_set))\n",
        "  FPR = np.zeros(len(threshold_set))\n",
        "  J = np.zeros(len(threshold_set))\n",
        "  i=0\n",
        "  for th in threshold_set:\n",
        "    TPR[i] = get_sensitivity(y_true, y_pred_prob, th)\n",
        "    spec = get_specificity(y_true, y_pred_prob, th)\n",
        "    FPR[i] = (1 - spec)\n",
        "    J[i] = TPR[i] - FPR[i]\n",
        "    i+=1\n",
        "  good_th = np.argmax(J)\n",
        "  return threshold_set[good_th]\n",
        "\n",
        "good_th = decide_th(y_true, y_pred_prob[:,1])\n",
        "print(good_th)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.48573000000000005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGmesRfT03PM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stat_dict, tpr, fpr, prec_list, rec_list = get_statistics(y_true, y_pred_prob[:,1], 0.5)\n",
        "print(stat_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McaraCg4064c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_prc(precision, recall):\n",
        "  plt.plot(recall, precision, 'r')\n",
        "  plt.xlabel(\"Recall\")\n",
        "  plt.ylabel(\"Precision\")\n",
        "  plt.title(\"Precision-Recall Curve\")\n",
        "  plt.show()\n",
        "\n",
        "def plot_roc(TPR, FPR):\n",
        "  plt.plot(FPR, TPR, 'r', label = \"ROC Curve\")\n",
        "  plt.plot(np.arange(0,1.05,0.05), np.arange(0,1.05,0.05), 'k', label = \"y=x line\")\n",
        "  plt.legend(loc = \"lower right\")\n",
        "  plt.xlabel('FPR')\n",
        "  plt.ylabel('TPR')\n",
        "  plt.title(\"ROC Curve\")\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKWTn4aY1AR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_roc(tpr, fpr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg_zQWyY1D_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_prc(prec_list, rec_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWnt60531HVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#torch.save(model.state_dict(), 'weights.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRQNpXEcD-eT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"ppv_set = []\n",
        "acc_set = []\n",
        "npv_set = []\n",
        "sens_set = []\n",
        "spec_set = []\n",
        "threshold_set1 = np.arange(0,1,0.05)\n",
        "for th in threshold_set1:\n",
        "  stat_dict1,_,_,_,_ = get_statistics(y_true, y_pred_prob[:,1], th)\n",
        "  acc_set.append(stat_dict1['Accuracy'])\n",
        "  npv_set.append(stat_dict1['NPV'])\n",
        "  spec_set.append(stat_dict1['Specificity'])\n",
        "  sens_set.append(stat_dict1['Sensitivity'])\n",
        "  ppv_set.append(stat_dict1['PPV'])\n",
        "plt.plot(threshold_set1, ppv_set,  label = \"PPV\")\n",
        "plt.plot(threshold_set1, acc_set,  label = \"Accuracy\")\n",
        "plt.plot(threshold_set1, npv_set,  label = \"NPV\")\n",
        "plt.plot(threshold_set1, sens_set,  label = \"Sensitivity\")\n",
        "plt.plot(threshold_set1, spec_set,  label = \"Specificity\")\n",
        "plt.xlabel('Thresholds')\n",
        "plt.legend(loc = \"best\")\n",
        "plt.show()\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
